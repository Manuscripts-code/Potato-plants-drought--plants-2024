# Article title

See related [Publications](https://github.com/janezlapajne/manuscripts)

### ğŸ” Introduction


**Abstarct** \
place abstract here

**Authors:** Author1, Author2, Author3 \
**Keywords:** Keyword1, Keyword2, Keyword3 \
**Published In:** Journal or Conference Name \
**Publication Date:** Month, Year 

### âš™ï¸ Environment setup

**Requirements (desired)**

* ğŸ® Sufficiently powerful GPU, min. 4GB VRAM
* ğŸ’¾ Min. 64 GB RAM
* ğŸ“¦ï¸ Min. 100 GB available storage memory

**Local setup**

Setup is written for Windows machine. However, the same setup is required for Linux machine.

1) Create and activate a virtual environment:

```bash
conda create -n env-eval python=3.9
conda activate env-eval
```

2) Install packages into the virtual environment:

```bash
pip install -r requirements.txt
```

3) Install Pytorch CUDA support if not automatically installed.

### ğŸ–¼ï¸ Dataset

Download the data from [Zenodo](10.5281/zenodo.7936850) and unzip to folder named `imagings`.
The folder structure should look like:

```
ğŸ“‚ imagings
â”œâ”€â”€ ğŸ“ imaging-1
â”‚   â”œâ”€â”€ ğŸ“„ 0_1_0__KK-K-04_KS-K-05_KK-S-03__imaging-1__1-22_20000_us_2x_HSNR02_ 2022-05-11T104633_corr_rad_f32.hdr
â”‚   â”œâ”€â”€ ğŸ“„ 0_1_0__KK-K-04_KS-K-05_KK-S-03__imaging-1__1-22_20000_us_2x_HSNR02_2022-05-11T104633_corr_rad_f32.img
â”‚   â””â”€â”€ ğŸ“„ ...
â”œâ”€â”€ ğŸ“ imaging-2
â”‚   â””â”€â”€ ğŸ“„ ...
â”œâ”€â”€ ğŸ“ imaging-3
â”‚   â””â”€â”€ ğŸ“„ ...
â”œâ”€â”€ ğŸ“ imaging-4
â”‚   â””â”€â”€ ğŸ“„ ...
â””â”€â”€ ğŸ“ imaging-5
    â””â”€â”€ ğŸ“„ ...
```

Then, create `.env` file in repository root (next to `.env.example`) and specify the **absolute** path to extracted data location.
For example, if the data is located in `C:\\Users\\janezla\\Documents\\imagings`, write the following in the `.env` file (without spaces and unusual characters):

```sh
DATA_DIR=C:\\Users\\janezla\\Documents\\imagings
```

### ğŸ“š How to use

**Train and evaluate**

Run the following command to train the model on training data and evaluate on testing data.

```bash
python main.py -c configs/krka/stratify/krka_stratify_54321.json -m train_test
```

Use different json config file accordingly.

**Observe experiments**

The experiments are automatically created by using mlflow tool. To start mlflow server run:

```bash
mlflow server -h 0.0.0.0 -p 8000 --backend-store-uri experiments/
```

The experiments could than be reached at <http://localhost:8000/>

**Generate results**

Use scripts and notebooks from `notebooks` directory to generate results, plots and classification metrics. 
For example, run `produce_results.py` script to generate the metrics and some results.

### ğŸ“¬ Contact

This project was initially developed by Janez Lapajne. If you have any questions or encounter any other problem, feel free to post an issue on Github.
